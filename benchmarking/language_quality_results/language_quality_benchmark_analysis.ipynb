{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means:\n",
      " naturalness          0.573559\n",
      "coherence            0.996281\n",
      "engagingness         9.906977\n",
      "groundedness         0.997282\n",
      "understandability    0.642903\n",
      "overall              2.623401\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviations:\n",
      " naturalness          0.216991\n",
      "coherence            0.041685\n",
      "engagingness         7.199907\n",
      "groundedness         0.024560\n",
      "understandability    0.199123\n",
      "overall              1.401436\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your JSON file\n",
    "file_path = '/rds/general/user/bsk18/home/final-bias-ilql/benchmarking/language_quality_results/original_original_language_quality_scores.json'\n",
    "\n",
    "# Read JSON data\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Assuming your data is under the 'original' key\n",
    "metrics_data = data['original']\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(metrics_data)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "means_original = df.mean()\n",
    "std_devs_original = df.std()\n",
    "\n",
    "# Print the results\n",
    "print(\"Means:\\n\", means_original)\n",
    "print(\"\\nStandard Deviations:\\n\", std_devs_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means:\n",
      " naturalness          0.573559\n",
      "coherence            0.996281\n",
      "engagingness         9.906977\n",
      "groundedness         0.997282\n",
      "understandability    0.642903\n",
      "overall              2.623401\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviations:\n",
      " naturalness          0.216991\n",
      "coherence            0.041685\n",
      "engagingness         7.199907\n",
      "groundedness         0.024560\n",
      "understandability    0.199123\n",
      "overall              1.401436\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your JSON file\n",
    "file_path = '/rds/general/user/bsk18/home/final-bias-ilql/benchmarking/language_quality_results/original_generated_language_quality_scores.json'\n",
    "\n",
    "# Read JSON data\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Assuming your data is under the 'original' key\n",
    "metrics_data = data['original']\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(metrics_data)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "means_generated = df.mean()\n",
    "std_devs_generated = df.std()\n",
    "\n",
    "# Print the results\n",
    "print(\"Means:\\n\", means_generated)\n",
    "print(\"\\nStandard Deviations:\\n\", std_devs_generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means:\n",
      " naturalness           0.166108\n",
      "coherence             0.736567\n",
      "engagingness         13.727743\n",
      "groundedness          0.302981\n",
      "understandability     0.187937\n",
      "overall               3.024267\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviations:\n",
      " naturalness          0.151883\n",
      "coherence            0.150482\n",
      "engagingness         5.217912\n",
      "groundedness         0.307319\n",
      "understandability    0.149840\n",
      "overall              1.139021\n",
      "dtype: float64\n",
      "Means:\n",
      " naturalness           0.170232\n",
      "coherence             0.737394\n",
      "engagingness         13.731133\n",
      "groundedness          0.305643\n",
      "understandability     0.191655\n",
      "overall               3.027211\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviations:\n",
      " naturalness          0.157419\n",
      "coherence            0.151421\n",
      "engagingness         5.232898\n",
      "groundedness         0.309696\n",
      "understandability    0.155429\n",
      "overall              1.145035\n",
      "dtype: float64\n",
      "Means:\n",
      " naturalness           0.358905\n",
      "coherence             0.873505\n",
      "engagingness         10.283504\n",
      "groundedness          0.839777\n",
      "understandability     0.387069\n",
      "overall               2.548552\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviations:\n",
      " naturalness          0.327523\n",
      "coherence            0.251104\n",
      "engagingness         5.119201\n",
      "groundedness         0.311207\n",
      "understandability    0.341739\n",
      "overall              1.094970\n",
      "dtype: float64\n",
      "Means:\n",
      " naturalness           0.165081\n",
      "coherence             0.736662\n",
      "engagingness         13.723533\n",
      "groundedness          0.303741\n",
      "understandability     0.186849\n",
      "overall               3.023173\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviations:\n",
      " naturalness          0.150463\n",
      "coherence            0.150573\n",
      "engagingness         5.214374\n",
      "groundedness         0.308010\n",
      "understandability    0.148547\n",
      "overall              1.137793\n",
      "dtype: float64\n",
      "Means:\n",
      " naturalness           0.209935\n",
      "coherence             0.222710\n",
      "engagingness         13.719105\n",
      "groundedness          0.164861\n",
      "understandability     0.226757\n",
      "overall               2.908674\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviations:\n",
      " naturalness          0.141451\n",
      "coherence            0.345964\n",
      "engagingness         5.211158\n",
      "groundedness         0.329542\n",
      "understandability    0.142805\n",
      "overall              1.158448\n",
      "dtype: float64\n",
      "Means:\n",
      " naturalness           0.469675\n",
      "coherence             0.972057\n",
      "engagingness         10.989284\n",
      "groundedness          0.966033\n",
      "understandability     0.534788\n",
      "overall               2.786367\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviations:\n",
      " naturalness          0.321807\n",
      "coherence            0.119815\n",
      "engagingness         3.548301\n",
      "groundedness         0.137715\n",
      "understandability    0.325808\n",
      "overall              0.730002\n",
      "dtype: float64\n",
      "Means:\n",
      " naturalness           0.462631\n",
      "coherence             0.982393\n",
      "engagingness         10.328792\n",
      "groundedness          0.981734\n",
      "understandability     0.493025\n",
      "overall               2.649715\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviations:\n",
      " naturalness          0.336099\n",
      "coherence            0.077445\n",
      "engagingness         4.451677\n",
      "groundedness         0.081442\n",
      "understandability    0.347055\n",
      "overall              0.893764\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your JSON file\n",
    "file_path = '/rds/general/user/bsk18/home/final-bias-ilql/benchmarking/language_quality_results/benchmark_language_quality_scores.json'\n",
    "\n",
    "# Read JSON data\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "debiasing_methods = [\"inlp-race\", \"inlp-gender\", \"Instructive-Debiasing\", \"sentence-debiasing-race\", \"sentence-debiasing-gender\"] \n",
    "means_benchmarking = []\n",
    "std_devs_benchmarking = []\n",
    "\n",
    "for method in debiasing_methods:\n",
    "    # Assuming your data is under the 'original' key\n",
    "    metrics_data = data[method]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(metrics_data)\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    means = df.mean()\n",
    "    std_devs = df.std()\n",
    "\n",
    "    means_benchmarking.append(means)\n",
    "    std_devs_benchmarking.append(std_devs)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Means:\\n\", means)\n",
    "    print(\"\\nStandard Deviations:\\n\", std_devs)\n",
    "\n",
    "# Path to your JSON file\n",
    "file_path = '/rds/general/user/bsk18/home/final-bias-ilql/benchmarking/language_quality_results/self_debiasing_language_quality_scores.json'\n",
    "\n",
    "# Read JSON data\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "debiasing_methods_extra = [\"self-debiasing-gpt2\",\"self-debiasing-debiased\"] \n",
    "\n",
    "for method in debiasing_methods_extra:\n",
    "    # Assuming your data is under the 'original' key\n",
    "    metrics_data = data[method]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(metrics_data)\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    means = df.mean()\n",
    "    std_devs = df.std()\n",
    "\n",
    "    means_benchmarking.append(means)\n",
    "    std_devs_benchmarking.append(std_devs)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Means:\\n\", means)\n",
    "    print(\"\\nStandard Deviations:\\n\", std_devs)\n",
    "\n",
    "debiasing_methods += debiasing_methods_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqs_benchmark_df = pd.DataFrame(columns=['method']+means.index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqs_benchmark_df['method'] = debiasing_methods\n",
    "lqs_benchmark_df.set_index(['method'], drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 inlp-race\n",
      "1 inlp-gender\n",
      "2 Instructive-Debiasing\n",
      "3 sentence-debiasing-race\n",
      "4 sentence-debiasing-gender\n",
      "5 self-debiasing-gpt2\n",
      "6 self-debiasing-debiased\n"
     ]
    }
   ],
   "source": [
    "for idx,method in enumerate(debiasing_methods):\n",
    "    print(idx, method)\n",
    "    for metric in means.index.to_list():\n",
    "        lqs_benchmark_df[metric].loc[method] = means_benchmarking[idx][metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.649715097115524"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_benchmarking[idx][metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naturalness</th>\n",
       "      <th>coherence</th>\n",
       "      <th>engagingness</th>\n",
       "      <th>groundedness</th>\n",
       "      <th>understandability</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inlp-race</th>\n",
       "      <td>0.166108</td>\n",
       "      <td>0.736567</td>\n",
       "      <td>13.727743</td>\n",
       "      <td>0.302981</td>\n",
       "      <td>0.187937</td>\n",
       "      <td>3.024267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inlp-gender</th>\n",
       "      <td>0.170232</td>\n",
       "      <td>0.737394</td>\n",
       "      <td>13.731133</td>\n",
       "      <td>0.305643</td>\n",
       "      <td>0.191655</td>\n",
       "      <td>3.027211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instructive-Debiasing</th>\n",
       "      <td>0.358905</td>\n",
       "      <td>0.873505</td>\n",
       "      <td>10.283504</td>\n",
       "      <td>0.839777</td>\n",
       "      <td>0.387069</td>\n",
       "      <td>2.548552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-debiasing-race</th>\n",
       "      <td>0.165081</td>\n",
       "      <td>0.736662</td>\n",
       "      <td>13.723533</td>\n",
       "      <td>0.303741</td>\n",
       "      <td>0.186849</td>\n",
       "      <td>3.023173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-debiasing-gender</th>\n",
       "      <td>0.209935</td>\n",
       "      <td>0.22271</td>\n",
       "      <td>13.719105</td>\n",
       "      <td>0.164861</td>\n",
       "      <td>0.226757</td>\n",
       "      <td>2.908674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-debiasing-gpt2</th>\n",
       "      <td>0.469675</td>\n",
       "      <td>0.972057</td>\n",
       "      <td>10.989284</td>\n",
       "      <td>0.966033</td>\n",
       "      <td>0.534788</td>\n",
       "      <td>2.786367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-debiasing-debiased</th>\n",
       "      <td>0.462631</td>\n",
       "      <td>0.982393</td>\n",
       "      <td>10.328792</td>\n",
       "      <td>0.981734</td>\n",
       "      <td>0.493025</td>\n",
       "      <td>2.649715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          naturalness coherence engagingness groundedness  \\\n",
       "method                                                                      \n",
       "inlp-race                    0.166108  0.736567    13.727743     0.302981   \n",
       "inlp-gender                  0.170232  0.737394    13.731133     0.305643   \n",
       "Instructive-Debiasing        0.358905  0.873505    10.283504     0.839777   \n",
       "sentence-debiasing-race      0.165081  0.736662    13.723533     0.303741   \n",
       "sentence-debiasing-gender    0.209935   0.22271    13.719105     0.164861   \n",
       "self-debiasing-gpt2          0.469675  0.972057    10.989284     0.966033   \n",
       "self-debiasing-debiased      0.462631  0.982393    10.328792     0.981734   \n",
       "\n",
       "                          understandability   overall  \n",
       "method                                                 \n",
       "inlp-race                          0.187937  3.024267  \n",
       "inlp-gender                        0.191655  3.027211  \n",
       "Instructive-Debiasing              0.387069  2.548552  \n",
       "sentence-debiasing-race            0.186849  3.023173  \n",
       "sentence-debiasing-gender          0.226757  2.908674  \n",
       "self-debiasing-gpt2                0.534788  2.786367  \n",
       "self-debiasing-debiased            0.493025  2.649715  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lqs_benchmark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqs_benchmark_df.loc['original'] = means_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naturalness</th>\n",
       "      <th>coherence</th>\n",
       "      <th>engagingness</th>\n",
       "      <th>groundedness</th>\n",
       "      <th>understandability</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inlp-race</th>\n",
       "      <td>0.166108</td>\n",
       "      <td>0.736567</td>\n",
       "      <td>13.727743</td>\n",
       "      <td>0.302981</td>\n",
       "      <td>0.187937</td>\n",
       "      <td>3.024267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inlp-gender</th>\n",
       "      <td>0.170232</td>\n",
       "      <td>0.737394</td>\n",
       "      <td>13.731133</td>\n",
       "      <td>0.305643</td>\n",
       "      <td>0.191655</td>\n",
       "      <td>3.027211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instructive-Debiasing</th>\n",
       "      <td>0.358905</td>\n",
       "      <td>0.873505</td>\n",
       "      <td>10.283504</td>\n",
       "      <td>0.839777</td>\n",
       "      <td>0.387069</td>\n",
       "      <td>2.548552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-debiasing-race</th>\n",
       "      <td>0.165081</td>\n",
       "      <td>0.736662</td>\n",
       "      <td>13.723533</td>\n",
       "      <td>0.303741</td>\n",
       "      <td>0.186849</td>\n",
       "      <td>3.023173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-debiasing-gender</th>\n",
       "      <td>0.209935</td>\n",
       "      <td>0.22271</td>\n",
       "      <td>13.719105</td>\n",
       "      <td>0.164861</td>\n",
       "      <td>0.226757</td>\n",
       "      <td>2.908674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-debiasing-gpt2</th>\n",
       "      <td>0.469675</td>\n",
       "      <td>0.972057</td>\n",
       "      <td>10.989284</td>\n",
       "      <td>0.966033</td>\n",
       "      <td>0.534788</td>\n",
       "      <td>2.786367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-debiasing-debiased</th>\n",
       "      <td>0.462631</td>\n",
       "      <td>0.982393</td>\n",
       "      <td>10.328792</td>\n",
       "      <td>0.981734</td>\n",
       "      <td>0.493025</td>\n",
       "      <td>2.649715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.573559</td>\n",
       "      <td>0.996281</td>\n",
       "      <td>9.906977</td>\n",
       "      <td>0.997282</td>\n",
       "      <td>0.642903</td>\n",
       "      <td>2.623401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          naturalness coherence engagingness groundedness  \\\n",
       "method                                                                      \n",
       "inlp-race                    0.166108  0.736567    13.727743     0.302981   \n",
       "inlp-gender                  0.170232  0.737394    13.731133     0.305643   \n",
       "Instructive-Debiasing        0.358905  0.873505    10.283504     0.839777   \n",
       "sentence-debiasing-race      0.165081  0.736662    13.723533     0.303741   \n",
       "sentence-debiasing-gender    0.209935   0.22271    13.719105     0.164861   \n",
       "self-debiasing-gpt2          0.469675  0.972057    10.989284     0.966033   \n",
       "self-debiasing-debiased      0.462631  0.982393    10.328792     0.981734   \n",
       "original                     0.573559  0.996281     9.906977     0.997282   \n",
       "\n",
       "                          understandability   overall  \n",
       "method                                                 \n",
       "inlp-race                          0.187937  3.024267  \n",
       "inlp-gender                        0.191655  3.027211  \n",
       "Instructive-Debiasing              0.387069  2.548552  \n",
       "sentence-debiasing-race            0.186849  3.023173  \n",
       "sentence-debiasing-gender          0.226757  2.908674  \n",
       "self-debiasing-gpt2                0.534788  2.786367  \n",
       "self-debiasing-debiased            0.493025  2.649715  \n",
       "original                           0.642903  2.623401  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lqs_benchmark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqs_benchmark_df.loc['generated'] = means_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naturalness</th>\n",
       "      <th>coherence</th>\n",
       "      <th>engagingness</th>\n",
       "      <th>groundedness</th>\n",
       "      <th>understandability</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>inlp-race</th>\n",
       "      <td>0.166108</td>\n",
       "      <td>0.736567</td>\n",
       "      <td>13.727743</td>\n",
       "      <td>0.302981</td>\n",
       "      <td>0.187937</td>\n",
       "      <td>3.024267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inlp-gender</th>\n",
       "      <td>0.170232</td>\n",
       "      <td>0.737394</td>\n",
       "      <td>13.731133</td>\n",
       "      <td>0.305643</td>\n",
       "      <td>0.191655</td>\n",
       "      <td>3.027211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instructive-Debiasing</th>\n",
       "      <td>0.358905</td>\n",
       "      <td>0.873505</td>\n",
       "      <td>10.283504</td>\n",
       "      <td>0.839777</td>\n",
       "      <td>0.387069</td>\n",
       "      <td>2.548552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-debiasing-race</th>\n",
       "      <td>0.165081</td>\n",
       "      <td>0.736662</td>\n",
       "      <td>13.723533</td>\n",
       "      <td>0.303741</td>\n",
       "      <td>0.186849</td>\n",
       "      <td>3.023173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-debiasing-gender</th>\n",
       "      <td>0.209935</td>\n",
       "      <td>0.22271</td>\n",
       "      <td>13.719105</td>\n",
       "      <td>0.164861</td>\n",
       "      <td>0.226757</td>\n",
       "      <td>2.908674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-debiasing-gpt2</th>\n",
       "      <td>0.469675</td>\n",
       "      <td>0.972057</td>\n",
       "      <td>10.989284</td>\n",
       "      <td>0.966033</td>\n",
       "      <td>0.534788</td>\n",
       "      <td>2.786367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-debiasing-debiased</th>\n",
       "      <td>0.462631</td>\n",
       "      <td>0.982393</td>\n",
       "      <td>10.328792</td>\n",
       "      <td>0.981734</td>\n",
       "      <td>0.493025</td>\n",
       "      <td>2.649715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.573559</td>\n",
       "      <td>0.996281</td>\n",
       "      <td>9.906977</td>\n",
       "      <td>0.997282</td>\n",
       "      <td>0.642903</td>\n",
       "      <td>2.623401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated</th>\n",
       "      <td>0.573559</td>\n",
       "      <td>0.996281</td>\n",
       "      <td>9.906977</td>\n",
       "      <td>0.997282</td>\n",
       "      <td>0.642903</td>\n",
       "      <td>2.623401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          naturalness coherence engagingness groundedness  \\\n",
       "method                                                                      \n",
       "inlp-race                    0.166108  0.736567    13.727743     0.302981   \n",
       "inlp-gender                  0.170232  0.737394    13.731133     0.305643   \n",
       "Instructive-Debiasing        0.358905  0.873505    10.283504     0.839777   \n",
       "sentence-debiasing-race      0.165081  0.736662    13.723533     0.303741   \n",
       "sentence-debiasing-gender    0.209935   0.22271    13.719105     0.164861   \n",
       "self-debiasing-gpt2          0.469675  0.972057    10.989284     0.966033   \n",
       "self-debiasing-debiased      0.462631  0.982393    10.328792     0.981734   \n",
       "original                     0.573559  0.996281     9.906977     0.997282   \n",
       "generated                    0.573559  0.996281     9.906977     0.997282   \n",
       "\n",
       "                          understandability   overall  \n",
       "method                                                 \n",
       "inlp-race                          0.187937  3.024267  \n",
       "inlp-gender                        0.191655  3.027211  \n",
       "Instructive-Debiasing              0.387069  2.548552  \n",
       "sentence-debiasing-race            0.186849  3.023173  \n",
       "sentence-debiasing-gender          0.226757  2.908674  \n",
       "self-debiasing-gpt2                0.534788  2.786367  \n",
       "self-debiasing-debiased            0.493025  2.649715  \n",
       "original                           0.642903  2.623401  \n",
       "generated                          0.642903  2.623401  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lqs_benchmark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index = ['original', 'self-debiasing-gpt2','inlp-race', 'inlp-gender', 'sentence-debiasing-race', 'sentence-debiasing-gender', \"self-debiasing-debiased\", 'Instructive-Debiasing', 'generated']\n",
    "lqs_benchmark_df = lqs_benchmark_df.reindex(new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naturalness</th>\n",
       "      <th>coherence</th>\n",
       "      <th>engagingness</th>\n",
       "      <th>groundedness</th>\n",
       "      <th>understandability</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-debiasing-gpt2</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.97</td>\n",
       "      <td>10.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inlp-race</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.74</td>\n",
       "      <td>13.73</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.19</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inlp-gender</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.74</td>\n",
       "      <td>13.73</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.19</td>\n",
       "      <td>3.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-debiasing-race</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.74</td>\n",
       "      <td>13.72</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.19</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-debiasing-gender</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.22</td>\n",
       "      <td>13.72</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-debiasing-debiased</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.98</td>\n",
       "      <td>10.33</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instructive-Debiasing</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.87</td>\n",
       "      <td>10.28</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated</th>\n",
       "      <td>0.57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           naturalness  coherence  engagingness  groundedness  \\\n",
       "method                                                                          \n",
       "original                          0.57       1.00          9.91          1.00   \n",
       "self-debiasing-gpt2               0.47       0.97         10.99          0.97   \n",
       "inlp-race                         0.17       0.74         13.73          0.30   \n",
       "inlp-gender                       0.17       0.74         13.73          0.31   \n",
       "sentence-debiasing-race           0.17       0.74         13.72          0.30   \n",
       "sentence-debiasing-gender         0.21       0.22         13.72          0.16   \n",
       "self-debiasing-debiased           0.46       0.98         10.33          0.98   \n",
       "Instructive-Debiasing             0.36       0.87         10.28          0.84   \n",
       "generated                         0.57       1.00          9.91          1.00   \n",
       "\n",
       "                           understandability  overall  \n",
       "method                                                 \n",
       "original                                0.64     2.62  \n",
       "self-debiasing-gpt2                     0.53     2.79  \n",
       "inlp-race                               0.19     3.02  \n",
       "inlp-gender                             0.19     3.03  \n",
       "sentence-debiasing-race                 0.19     3.02  \n",
       "sentence-debiasing-gender               0.23     2.91  \n",
       "self-debiasing-debiased                 0.49     2.65  \n",
       "Instructive-Debiasing                   0.39     2.55  \n",
       "generated                               0.64     2.62  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lqs_benchmark_df = lqs_benchmark_df.astype(float)\n",
    "lqs_benchmark_df = lqs_benchmark_df.round(2)\n",
    "lqs_benchmark_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqs_benchmark_df = lqs_benchmark_df.astype(str)\n",
    "std_devs_original = std_devs_original.round(2).astype(str)\n",
    "std_devs_generated = std_devs_generated.round(2).astype(str)\n",
    "std_devs_benchmarking = [std_dev_bench.round(2).astype(str) for std_dev_bench in std_devs_benchmarking]\n",
    "lqs_benchmark_df.loc['original'] = [lqs_benchmark_df.loc['original'].loc[idx] + \"±\" + std_devs_original.loc[idx] for idx in std_devs_original.index]\n",
    "lqs_benchmark_df.loc['generated'] = [lqs_benchmark_df.loc['generated'].loc[idx] + \"±\" + std_devs_generated.loc[idx] for idx in std_devs_generated.index]\n",
    "\n",
    "for idx, bench in enumerate(debiasing_methods):\n",
    "    bench_df = std_devs_benchmarking[idx]\n",
    "    lqs_benchmark_df.loc[bench] = [lqs_benchmark_df.loc[bench][idx1] + \"±\" + bench_df[idx1] for idx1 in bench_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naturalness</th>\n",
       "      <th>coherence</th>\n",
       "      <th>groundedness</th>\n",
       "      <th>understandability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.57±0.22</td>\n",
       "      <td>1.0±0.04</td>\n",
       "      <td>1.0±0.02</td>\n",
       "      <td>0.64±0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-debiasing-gpt2</th>\n",
       "      <td>0.47±0.32</td>\n",
       "      <td>0.97±0.12</td>\n",
       "      <td>0.97±0.14</td>\n",
       "      <td>0.53±0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inlp-race</th>\n",
       "      <td>0.17±0.15</td>\n",
       "      <td>0.74±0.15</td>\n",
       "      <td>0.3±0.31</td>\n",
       "      <td>0.19±0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inlp-gender</th>\n",
       "      <td>0.17±0.16</td>\n",
       "      <td>0.74±0.15</td>\n",
       "      <td>0.31±0.31</td>\n",
       "      <td>0.19±0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-debiasing-race</th>\n",
       "      <td>0.17±0.15</td>\n",
       "      <td>0.74±0.15</td>\n",
       "      <td>0.3±0.31</td>\n",
       "      <td>0.19±0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence-debiasing-gender</th>\n",
       "      <td>0.21±0.14</td>\n",
       "      <td>0.22±0.35</td>\n",
       "      <td>0.16±0.33</td>\n",
       "      <td>0.23±0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-debiasing-debiased</th>\n",
       "      <td>0.46±0.34</td>\n",
       "      <td>0.98±0.08</td>\n",
       "      <td>0.98±0.08</td>\n",
       "      <td>0.49±0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instructive-Debiasing</th>\n",
       "      <td>0.36±0.33</td>\n",
       "      <td>0.87±0.25</td>\n",
       "      <td>0.84±0.31</td>\n",
       "      <td>0.39±0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generated</th>\n",
       "      <td>0.57±0.22</td>\n",
       "      <td>1.0±0.04</td>\n",
       "      <td>1.0±0.02</td>\n",
       "      <td>0.64±0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          naturalness  coherence groundedness  \\\n",
       "method                                                          \n",
       "original                    0.57±0.22   1.0±0.04     1.0±0.02   \n",
       "self-debiasing-gpt2         0.47±0.32  0.97±0.12    0.97±0.14   \n",
       "inlp-race                   0.17±0.15  0.74±0.15     0.3±0.31   \n",
       "inlp-gender                 0.17±0.16  0.74±0.15    0.31±0.31   \n",
       "sentence-debiasing-race     0.17±0.15  0.74±0.15     0.3±0.31   \n",
       "sentence-debiasing-gender   0.21±0.14  0.22±0.35    0.16±0.33   \n",
       "self-debiasing-debiased     0.46±0.34  0.98±0.08    0.98±0.08   \n",
       "Instructive-Debiasing       0.36±0.33  0.87±0.25    0.84±0.31   \n",
       "generated                   0.57±0.22   1.0±0.04     1.0±0.02   \n",
       "\n",
       "                          understandability  \n",
       "method                                       \n",
       "original                           0.64±0.2  \n",
       "self-debiasing-gpt2               0.53±0.33  \n",
       "inlp-race                         0.19±0.15  \n",
       "inlp-gender                       0.19±0.16  \n",
       "sentence-debiasing-race           0.19±0.15  \n",
       "sentence-debiasing-gender         0.23±0.14  \n",
       "self-debiasing-debiased           0.49±0.35  \n",
       "Instructive-Debiasing             0.39±0.34  \n",
       "generated                          0.64±0.2  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lqs_benchmark_df = lqs_benchmark_df[['naturalness', 'coherence', 'groundedness', 'understandability']]\n",
    "lqs_benchmark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      " & naturalness & coherence & groundedness & understandability \\\\\n",
      "method &  &  &  &  \\\\\n",
      "\\midrule\n",
      "original & 0.57±0.22 & 1.0±0.04 & 1.0±0.02 & 0.64±0.2 \\\\\n",
      "self-debiasing-gpt2 & 0.47±0.32 & 0.97±0.12 & 0.97±0.14 & 0.53±0.33 \\\\\n",
      "inlp-race & 0.17±0.15 & 0.74±0.15 & 0.3±0.31 & 0.19±0.15 \\\\\n",
      "inlp-gender & 0.17±0.16 & 0.74±0.15 & 0.31±0.31 & 0.19±0.16 \\\\\n",
      "sentence-debiasing-race & 0.17±0.15 & 0.74±0.15 & 0.3±0.31 & 0.19±0.15 \\\\\n",
      "sentence-debiasing-gender & 0.21±0.14 & 0.22±0.35 & 0.16±0.33 & 0.23±0.14 \\\\\n",
      "self-debiasing-debiased & 0.46±0.34 & 0.98±0.08 & 0.98±0.08 & 0.49±0.35 \\\\\n",
      "Instructive-Debiasing & 0.36±0.33 & 0.87±0.25 & 0.84±0.31 & 0.39±0.34 \\\\\n",
      "generated & 0.57±0.22 & 1.0±0.04 & 1.0±0.02 & 0.64±0.2 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lqs_benchmark_df.to_latex(escape=False, float_format = \"%.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_bias_ilql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
