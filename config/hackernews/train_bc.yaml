defaults:
  - model: bc_lm
  - dataset@train_dataset: list_train
  - dataset@eval_dataset: list_test
  - evaluator: bc_evaluator
  - _self_

train_dataset:
  cache_id: d_train
  data:
    cache_id: train_raw_data
    cache_path: null
    reward_shift: 0.0
    reward_scale: 1.0
    reward_f:
      # name: hackernews_reward
      name: score_human_reward
      job_descriptions_path: data/hackernews_rl_dataset/
      index_path: data/hackernews_rl_dataset/train_idxs.json
  max_len: 1024
  resample_timeout: 0.0
  include_parent: true

eval_dataset:
  cache_id: d_test
  data:
    cache_id: test_raw_data
    cache_path: null
    reward_shift: 0.0
    reward_scale: 1.0
    reward_f:
      # name: hackernews_reward
      name: score_human_reward
      job_descriptions_path: data/hackernews_rl_dataset/
      index_path: data/hackernews_rl_dataset/test_idxs.json
  max_len: 1024
  resample_timeout: 0.0
  include_parent: true

model:
  transition_weight: 0.0
  dataset:
    name: hackernews_list_dataset
    cache_id: d_train
  load:
    checkpoint_path: null
    strict_load: true

evaluator:
  env:
    reward_shift: 0.0
    reward_scale: 1.0
    data:
      name: hackernews_rl_dataset
      cache_id: test_raw_data
    reward_f:
      name: hackernews_reward
    include_parent: true
  verbose: true
  kind: sample
  generation_kwargs:
    max_generation_len: 128
    num_generations: 1

train:
  save_checkpoint_dir: outputs/hackernews/conditional_hackernews_official_bc_test1/
  optim_state_path: null
  epochs: 48
  dataloader_workers: 0
  bsize: 1
  grad_accum_steps: 64
  log_every: 4096
  eval_every: 4096
  save_every: 4096
  max_checkpoints: 1
  eval_bsize: 1
  eval_batches: 16
  lr: 1e-4
  weight_decay: 0.00
  max_steps: null
  loss: {}

wandb:
  use_wandb: false
  wandb_project: hackernews_iql
