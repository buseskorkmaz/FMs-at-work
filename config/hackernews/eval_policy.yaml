defaults:
  - model: per_token_iql
  - dataset: list_eval
  - evaluator: iql_evaluator
  - _self_

dataset:
  cache_id: d
  data:
    cache_id: raw_data
    cache_path: null
    reward_shift: 0.0
    reward_scale: 1.0
    reward_f:
      name: hackernews_reward
      job_descriptions_path: data/hackernews_rl_dataset/
      index_path: data/hackernews_rl_dataset/eval_idxs.json
  max_len: 1024
  cuttoff: null
  resample_timeout: 0.05
  include_parent: true

model:
  alpha: 0.005
  gamma: 0.99
  beta: 64
  transition_weight: 0.0
  clip_weight: null
  value_max: null
  value_min: null
  detach_v: false
  detach_q: false
  detach_pi: false
  double_q: true
  seperate_policy: true
  seperate_target: true
  tau: 0.6
  exp_weights: true
  dm_margin: 0.0
  advanced_mlp: false
  cql_temp: 1.0
  gpt2:
    lm_head: true
    from_pretrained: true
  dataset:
    name: hackernews_list_dataset
    cache_id: d
  load:
    checkpoint_path: outputs/hackernews/llama/frozen_512_bios_no_offload_5_epoch_awac0-5/model_7499.pkl
    strict_load: true
  llama:
    lm_head: true
    from_pretrained: true
  flant5:
    lm_head: true
    from_pretrained: true
  bloom3b:
    lm_head: true
    from_pretrained: true
  openllama:
    lm_head: true
    from_pretrained: true

evaluator:
  env:
    reward_shift: 0.0
    reward_scale: 1.0
    data:
      name: hackernews_rl_dataset
      cache_id: raw_data
    reward_f:
      name: hackernews_reward
      job_descriptions_path: data/hackernews_rl_dataset/
      index_path: data/hackernews_rl_dataset/eval_idxs.json
    include_parent: true
  verbose: true
  kind: sample
  generation_kwargs:
    max_generation_len: 512
    # beam_width: 1
    temp: 1.0
    top_k: null
    top_p: null
    exp_adv: true
    adv_weight: 8.0
    adv_clip: null
    include_logits: true
    include_adv: true
    num_generations: 1
    rerank_log_prob_weight: 0.0
    rerank_advantage_weight: 1.0

eval:
  dataloader_workers: 1
  bsize: 1
  batches: 400
  print_every: 4
  seed: 0
  log_save_path: outputs/hackernews/llama/eval/frozen_512_hn_no_offload_5_epoch-beta64_awac025/eval_logs.pkl
  loss:
    v_loss_weight: 1.0
    q_loss_weight: 1.0
    awac_weight: 0.25
    cql_loss_weight: 0.25
    mc_returns: false

wandb:
  use_wandb: true
  wandb_project: hackernews_iql_llama_eval
