{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/busesibelkorkmaz/.cache/huggingface/datasets/dansbecker___parquet/dansbecker--hackernews_hiring_posts-bf0ef9ae958fdb08/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc7ed7cbcad4c1c99bdebc961a789cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"dansbecker/hackernews_hiring_posts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_10_rows = dataset[\"hiring\"][slice(None, 10, None)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Scoot &#38; Doodle (SF/Remote)\\nRaised $2.25M in funding and user engagement averages 30 minutes/session.\\nLooking for  Rails, iOS, NodeJS devs.\\nLearn more - <a href=\"http://blog.goodsense.io/jobs-and-projects\" >http://blog.goodsense.io/jobs-and-projects</a>\\nIf you want to talk about other projects contact me here - <a href=\"http://blog.goodsense.io/contact\" >http://blog.goodsense.io/contact</a>',\n",
       "  'Chambéry, France and Lausanne, Switzerland - Python and Javascript devs - geospatial and business\\nAll open source.\\nGeospatial development is primarily Javascript (OpenLayers, Ext.js) and Python (Pylons, SQLAlchemy, etc.).\\nBusiness development is Python (OpenERP).\\nFull list of positions: <a href=\"http://www.camptocamp.com/en/careers\" >http://www.camptocamp.com/en/careers</a>',\n",
       "  'Portland, OR/San Francisco - <a href=\"http://newrelic.com/about/jobs\" >http://newrelic.com/about/jobs</a>\\nNew Relic is growing and has several technical (and non-technical) positions.  If you\\'ve got skills in Ruby, Java, C, or iOS, and want to work at one of the coolest companies around, give us a shout.\\nWe are passionate, possibly even crazy, about application performance management (APM). Our mission is to make web applications run better, to make the internet more productive, and to make life easier for developers and devops. We are turning the APM marketplace upside down by providing SaaS products that deliver high-value functionality previously only available through enterprise software. We are well above 17,000 customers. And with your help we’ll get to 10x that number.\\n[H1B] is fine.  Usually no [REMOTE] but we have made exceptions.  We\\'re losing our [INTERN] to college so that\\'s also a possibility.',\n",
       "  'Boston, MA - Associate Software Engineer (Local, Full-time) - Communispace (www.communispace.com)\\nWe are a small team within a medium-sized company looking to deepen our bench and increase our capabilities through the addition of great engineering talent.\\nA bit about us:\\n* We\\'re the leader in market research online communities and develop software to enable consumer collaboration.\\n* We use the latest tools, in the past few months the biggest focus has been on JavaScript, ASP.NET MVC, and Objective-C, but Java (Android) is getting added to the mix soon. We operate in a continuous integration environment, and we have a passion for  writing beautiful code validated by automated tests. If you have used GitHub, Jenkins, Selenium and Visual Studio in the past you\\'ll be very comfortable here.\\n* We apply Lean-Agile principles (specifically Kanban) to a large extent, and though we are diligent we are far from dogmatic; getting stuff done is job #1.\\n* We hold two hackathons per year: one for engineering and one for the entire company!\\nA bit about you:\\n* You\\'re interested in joining a small team of experienced software engineers and want to touch lots of different parts of the product and platform.\\n* You always want to get up to speed quickly and constantly challenge yourself to learn new things.\\n* You love solving interesting problems with technology.\\n* You just plain love technology!\\n* You want a work environment characterized by a strong culture where you are expected to lean-in but it\\'s okay to kick-back (usually with a good beer in hand).\\nWe are located near Boston\\'s Innovation District and just a short walk from South Station. We offer a competitive salary and great benefits. I can honestly say that I love coming in to work every day and I think most HN readers would find likewise. If you are interested, learn more about us and submit an application here: <a href=\"http://www.communispace.com/careers/careers.aspx?jvi=oVyIXfwS\" >. You can email me with questions specific to the role at clogan [at] communispace.com. Please use the subject line: \"Associate Engineer - HN\". Applicants only. No recruiters!',\n",
       "  'DICOM Grid - Phoenix AZ, or REMOTE, no H1B, US only - JavaScript Developer\\nDICOM Grid, a SaaS start-up in the healthcare technology field, is looking for a JavaScript developer to maintain and enhance DICOM Grid’s front-end medical image sharing and reading web application. You will report to the Director of Dev Ops.\\nFamiliarity with modern front-end web development is essential, including but not limited to HTML5, CSS, JavaScript, LESS, JQuery, Underscore, Handlebars, Backbone. Experience working in the medical industry (DICOM, HL7, PACS, etc.) would be a bonus, but is not required.\\nThe ideal candidate would be able to work independently with minimal supervision, and be enthusiastic about keeping up-to-date with the latest web technologies.\\nThe team is distributed with team members working remotely in Phoenix, Los Angeles, Boston, and New York.\\nPosition Responsibilities\\n- Plan, evaluate, implement, test and document new features and bug fixes for the DICOM Grid web application.\\n- Work with other development team members to integrate with backend services.\\n- Work with DevOps to deploy code into our production and UAT environments.\\n- Work with customers and professional services to gather requirements.\\n- Conform to company standard operating procedures.\\nWhat qualifies you to join?\\n- A combination of a college degree in CS, Math, Physics, or related, relevant work experience, and/or a strong open source portfolio.\\n- General interest in the healthcare field.\\n- Strong communication and interpersonal skills.\\n- High enthusiasm and desire to work on an entrepreneurial team.\\n- Roll-up-the sleeves attitude is a must.\\n- Meticulous attention to detail with strong organization skills\\n- Heavy emphasis will be placed on problem solving skills, personal initiative and good people management/relationship skills. Sense of humor is mandatory.\\nLogistics\\n- This is virtual position, you must be able to work from home effectively\\n- Base salary and stock options depend on experience; health insurance, paid holidays and vacation are part of the package.\\nSend your resume along with links to your StackOverflow, GitHub profiles, etc. to pfreeman+REDACTED_EMAIL. For bonus points, include a solution to the following short task, including code in JavaScript or the frontend language of your choice: given a JSON object conforming to the schema { value: ..., collapsed: (true|false), children: [...] }, where children is an array of objects conforming to the same schema, and a function render taking values to DOM elements, layout the information for read-only display, with the ability to expand/collapse individual nodes. The aim of the exercise is to demonstrate familiarity with Javascript, so a very basic UI is all that is needed.',\n",
       "  'San Francisco, CA and Vancouver, BC\\nThe Systems Software team at OpenDNS is building a platform as a service to support our product engineering teams. We\\'re looking for engineers that have a passion for distributed systems, enjoy writing code, and love delighting customers with their product.\\nThe compute side of the PaaS is built around Docker. We\\'re building out across 24 datacenters. And, have big plans for the remainder of the year and 2015. This is a great opportunity to make an impact at a fast growing company.\\nWe\\'ve started talking about some of what our team is up to:\\n<a href=\"http://engineering.opendns.com/2014/10/22/docker-at-opendns/\" >\\n<a href=\"http://engineering.opendns.com/2014/09/03/docker-private-registry-authentication/\" >\\n<a href=\"http://engineering.opendns.com/2014/07/01/ip-routing-aws-docker/\" >\\nResumes can be submitted here:\\n<a href=\"http://hire.jobvite.com/CompanyJobs/Careers.aspx?k=Job&amp;c=q53..\" >.\\nYou can also reach out to me directly, REDACTED_EMAIL',\n",
       "  \"Synaptive Medical - Full time in Toronto.\\nNewly formed Medical device start up in Toronto, young and growing quickly. We're building equipment and applications for neurosurgical procedures.\\nIt's a great group of engineers with a lot of energy and applications we all believe in.\\nCurrent looking for people in many roles, such as:\\n   - Software development\\n   - Software test\\n   - Scientific software development\\n   - Embedded systems\\n   - Mechatronics\\n   - Optomechanical\\n   - Systems\\n   - User interface\\n\\nHighly relevant areas of experience for various roles:\\n   - Medical device industry\\n   - Medical imaging\\n   - MRI and MRI physics\\n   - Spectroscopy and endoscopy\\n   - Data converters (ADC/DAC)\\n   - FPGA\\n   - High performance interconnects\\n   - Realtime systems\\n   - Data streaming\\n   - Signal processing (image and/or video)\\n   - Neuroanatomy\\n   - Surgical suite equipment\\n   - Standards: ISO 13485, IEC 60601, ISO 14971, IEC 62304\\n\\nPosting and application details at: synaptivemedical.com\\n(or contact me: simon at the same domain.)\",\n",
       "  'Bellevue, WA - Senior Software Engineer - ClassifiedAds.com\\nI don\\'t work directly with this arm of our company, but here\\'s more details on the job description: <a href=\"http://www.classifiedads.com/technical_jobs-ad4787967.htm\" >http://www.classifiedads.com/technical_jobs-ad4787967.htm</a>',\n",
       "  'Palo Alto, CA - Comprehend Systems (YC W11)\\nHiring frontend and backend developers with solid CS skills to help us make cross-datasource visualization and analytics software.\\nemail me {my username}REDACTED_EMAIL or visit <a href=\"http://www.comprehend.com\" >http://www.comprehend.com</a>',\n",
       "  'WebCanada: Lead Platform Engineer / Architect\\nToronto, ON, Canada\\nAre you an experienced web developer?  Do you know MVC inside out?  Do you want to work on a development framework and CMS?\\nWebCanada is currently searching for an Architect to lead development of WebCanada\\'s Live CMS framework and content management system.  You will be responsible for adding features to make our CMS even more intuitive and easy to use, common modules for re-use across projects and will be a technical resource on complex projects.\\nIf you are interested, please check out the link below for more information:\\n<a href=\"http://webcanada.theresumator.com/apply/hw2ehE/SENIOR-PLATFORM-ENGINEER.html\" >http://webcanada.theresumator.com/apply/hw2ehE/SENIOR-PLATFO...</a>'],\n",
       " 'CommentTime': ['2013-04-01 19:42:31 UTC',\n",
       "  '2012-05-01 14:49:09 UTC',\n",
       "  '2012-05-01 14:49:36 UTC',\n",
       "  '2013-08-01 23:18:13 UTC',\n",
       "  '2014-02-03 17:15:55 UTC',\n",
       "  '2014-12-01 21:10:25 UTC',\n",
       "  '2013-06-01 15:49:10 UTC',\n",
       "  '2011-11-01 16:39:25 UTC',\n",
       "  '2011-11-01 16:41:36 UTC',\n",
       "  '2013-03-02 14:35:24 UTC'],\n",
       " 'CommentAuthor': ['sherm8n',\n",
       "  'twp',\n",
       "  'sgrock',\n",
       "  'clogan',\n",
       "  'paf31',\n",
       "  'transitorykris',\n",
       "  'ska',\n",
       "  'InfinityX0',\n",
       "  'rmorrison',\n",
       "  'MattBelanger'],\n",
       " 'ParentTitle': ['Ask HN: Who is hiring? (April 2013)',\n",
       "  'Ask HN: Who Is Hiring? (May 2012)',\n",
       "  'Ask HN: Who Is Hiring? (May 2012)',\n",
       "  'Ask HN: Who is hiring? (August 2013)',\n",
       "  'Ask HN: Who is hiring? (February 2014)',\n",
       "  'Ask HN: Who is hiring? (December 2014)',\n",
       "  'Ask HN: Who is hiring? (June 2013)',\n",
       "  'Ask HN: Who is Hiring? (November 2011)',\n",
       "  'Ask HN: Who is Hiring? (November 2011)',\n",
       "  'Ask HN: Who is hiring? (March 2013)']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_10_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    freelancer: Dataset({\n",
       "        features: ['text', 'CommentTime', 'CommentAuthor', 'ParentTitle'],\n",
       "        num_rows: 15266\n",
       "    })\n",
       "    hiring: Dataset({\n",
       "        features: ['text', 'CommentTime', 'CommentAuthor', 'ParentTitle'],\n",
       "        num_rows: 75974\n",
       "    })\n",
       "    wants_to_be_hired: Dataset({\n",
       "        features: ['text', 'CommentTime', 'CommentAuthor', 'ParentTitle'],\n",
       "        num_rows: 20262\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'CommentTime', 'CommentAuthor', 'ParentTitle'],\n",
       "    num_rows: 75974\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"hiring\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiring_df  = dataset[\"hiring\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/busesibelkorkmaz/.cache/huggingface/datasets/dansbecker___parquet/dansbecker--hackernews_hiring_posts-bf0ef9ae958fdb08/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-19b3397aceccf5ac_*_of_00008.arrow\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(row):\n",
    "    text = str(row[\"text\"])\n",
    "    text = re.sub(\"\\n\", '', text)\n",
    "    text = re.sub('\"', '', text)\n",
    "\n",
    "    first_step = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    second_step = re.sub(r'<a href=+|>+', '', first_step)\n",
    "\n",
    "    return {\"clean_text\": second_step}\n",
    "\n",
    "dataset[\"hiring\"] = dataset[\"hiring\"].map(preprocess_text, num_proc=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hiring_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hiring_df\u001b[39m.\u001b[39mloc[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hiring_df' is not defined"
     ]
    }
   ],
   "source": [
    "hiring_df.loc[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chambéry, France and Lausanne, Switzerland - Python and Javascript devs - geospatial and business\\nAll open source.\\nGeospatial development is primarily Javascript (OpenLayers, Ext.js) and Python (Pylons, SQLAlchemy, etc.).\\nBusiness development is Python (OpenERP).\\nFull list of positions: <a href=\"http://www.camptocamp.com/en/careers\" >http://www.camptocamp.com/en/careers</a>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiring_df.loc[1][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>CommentTime</th>\n",
       "      <th>CommentAuthor</th>\n",
       "      <th>ParentTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Location: Pittsburgh, PA\\nRemote: OK\\nWilling ...</td>\n",
       "      <td>2014-08-01 15:20:48 UTC</td>\n",
       "      <td>mtdavis</td>\n",
       "      <td>Ask HN: Who wants to be hired? (August 2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n  Location: East coast, US\\n  Remote: Yes\\n ...</td>\n",
       "      <td>2021-09-03 03:15:41 UTC</td>\n",
       "      <td>kvg8C091</td>\n",
       "      <td>Ask HN: Who wants to be hired? (September 2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Location: Germany\\nRemote: yes (but would pref...</td>\n",
       "      <td>2019-02-02 14:52:35 UTC</td>\n",
       "      <td>kleinfreund</td>\n",
       "      <td>Ask HN: Who wants to be hired? (February 2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Location: Birmingham, UK\\nRemote: Preferred\\nW...</td>\n",
       "      <td>2021-08-04 13:35:08 UTC</td>\n",
       "      <td>Jefro118</td>\n",
       "      <td>Ask HN: Who wants to be hired? (August 2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Location: US East Coast\\nWilling to Relocate: ...</td>\n",
       "      <td>2019-03-01 19:55:30 UTC</td>\n",
       "      <td>LongTermBond007</td>\n",
       "      <td>Ask HN: Who wants to be hired? (March 2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20257</th>\n",
       "      <td>Location: Chicago, IL\\nRemote: Will consider\\n...</td>\n",
       "      <td>2017-07-08 09:05:06 UTC</td>\n",
       "      <td>rwesty</td>\n",
       "      <td>Ask HN: Who wants to be hired? (July 2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20258</th>\n",
       "      <td>Location: Rome, Italy\\nRemote: YES\\nWilling to...</td>\n",
       "      <td>2017-07-08 12:39:13 UTC</td>\n",
       "      <td>eloquentbit</td>\n",
       "      <td>Ask HN: Who wants to be hired? (July 2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20259</th>\n",
       "      <td>Location: Montreal, Quebec (Canada)\\nRemote: N...</td>\n",
       "      <td>2017-07-05 18:12:05 UTC</td>\n",
       "      <td>ajgaba</td>\n",
       "      <td>Ask HN: Who wants to be hired? (July 2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20260</th>\n",
       "      <td>Location: Seattle, WA\\nRemote: yes/exclusively...</td>\n",
       "      <td>2017-07-03 16:33:10 UTC</td>\n",
       "      <td>fuzzy-logic</td>\n",
       "      <td>Ask HN: Who wants to be hired? (July 2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20261</th>\n",
       "      <td>Location: India\\nRemote: Yes\\nWilling to reloc...</td>\n",
       "      <td>2017-07-04 16:17:41 UTC</td>\n",
       "      <td>kshk123</td>\n",
       "      <td>Ask HN: Who wants to be hired? (July 2017)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20262 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Location: Pittsburgh, PA\\nRemote: OK\\nWilling ...   \n",
       "1      \\n  Location: East coast, US\\n  Remote: Yes\\n ...   \n",
       "2      Location: Germany\\nRemote: yes (but would pref...   \n",
       "3      Location: Birmingham, UK\\nRemote: Preferred\\nW...   \n",
       "4      Location: US East Coast\\nWilling to Relocate: ...   \n",
       "...                                                  ...   \n",
       "20257  Location: Chicago, IL\\nRemote: Will consider\\n...   \n",
       "20258  Location: Rome, Italy\\nRemote: YES\\nWilling to...   \n",
       "20259  Location: Montreal, Quebec (Canada)\\nRemote: N...   \n",
       "20260  Location: Seattle, WA\\nRemote: yes/exclusively...   \n",
       "20261  Location: India\\nRemote: Yes\\nWilling to reloc...   \n",
       "\n",
       "                   CommentTime    CommentAuthor  \\\n",
       "0      2014-08-01 15:20:48 UTC          mtdavis   \n",
       "1      2021-09-03 03:15:41 UTC         kvg8C091   \n",
       "2      2019-02-02 14:52:35 UTC      kleinfreund   \n",
       "3      2021-08-04 13:35:08 UTC         Jefro118   \n",
       "4      2019-03-01 19:55:30 UTC  LongTermBond007   \n",
       "...                        ...              ...   \n",
       "20257  2017-07-08 09:05:06 UTC           rwesty   \n",
       "20258  2017-07-08 12:39:13 UTC      eloquentbit   \n",
       "20259  2017-07-05 18:12:05 UTC           ajgaba   \n",
       "20260  2017-07-03 16:33:10 UTC      fuzzy-logic   \n",
       "20261  2017-07-04 16:17:41 UTC          kshk123   \n",
       "\n",
       "                                           ParentTitle  \n",
       "0         Ask HN: Who wants to be hired? (August 2014)  \n",
       "1      Ask HN: Who wants to be hired? (September 2021)  \n",
       "2       Ask HN: Who wants to be hired? (February 2019)  \n",
       "3         Ask HN: Who wants to be hired? (August 2021)  \n",
       "4          Ask HN: Who wants to be hired? (March 2019)  \n",
       "...                                                ...  \n",
       "20257       Ask HN: Who wants to be hired? (July 2017)  \n",
       "20258       Ask HN: Who wants to be hired? (July 2017)  \n",
       "20259       Ask HN: Who wants to be hired? (July 2017)  \n",
       "20260       Ask HN: Who wants to be hired? (July 2017)  \n",
       "20261       Ask HN: Who wants to be hired? (July 2017)  \n",
       "\n",
       "[20262 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"wants_to_be_hired\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/busesibelkorkmaz/miniconda3/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:164: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> J'aime la programmation</s>\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "\n",
    "# Define your prompt\n",
    "prompt = \"translate English to French: I love programming\"\n",
    "\n",
    "# Encode the prompt\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate a response\n",
    "outputs = model.generate(inputs, max_length=40, num_return_sequences=1, temperature=0.7)\n",
    "\n",
    "# Decode the output\n",
    "decoded_output = tokenizer.decode(outputs[0])\n",
    "\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> 'Chambéry, France and Lausanne, Switzerland - Python and Javascript devs - geospatial and business development': 'All open source. Javascript (OpenLayers, Ext.js, etc.) and Python (Pylons, SQLAlchemy, etc.). Business development is Python (OpenERP).'</s>\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "\n",
    "# Define your prompt\n",
    "prompt = \"Parse this job description as bullet points of 'location(s)' and 'technologies': 'Chambéry, France and Lausanne, Switzerland - Python and Javascript devs - geospatial and business\\nAll open source.\\nGeospatial development is primarily Javascript (OpenLayers, Ext.js) and Python (Pylons, SQLAlchemy, etc.).\\nBusiness development is Python (OpenERP).'\"\n",
    "\n",
    "# Encode the prompt\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate a response\n",
    "outputs = model.generate(inputs, max_length=200, num_return_sequences=1, temperature=0.7)\n",
    "\n",
    "# Decode the output\n",
    "decoded_output = tokenizer.decode(outputs[0])\n",
    "\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# # Specify the models\n",
    "# models = ['dslim/bert-base-NER']\n",
    "\n",
    "# # Input text\n",
    "# text = \"Chambéry, France and Lausanne, Switzerland - Python and Javascript devs - geospatial and business\\nAll open source.\\nGeospatial development is primarily Javascript (OpenLayers, Ext.js) and Python (Pylons, SQLAlchemy, etc.).\\nBusiness development is Python (OpenERP)\"\n",
    "\n",
    "# # Process the text with each model\n",
    "# for model in models:\n",
    "#     ner = pipeline(\"ner\", model=model)\n",
    "#     entities = ner(text)\n",
    "#     print(f\"Entities recognized by {model}:\")\n",
    "#     for entity in entities:\n",
    "#         print(f\"{entity['entity']}: {entity['word']}\")\n",
    "#     print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/busesibelkorkmaz/miniconda3/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "/Users/busesibelkorkmaz/miniconda3/lib/python3.10/site-packages/transformers/generation_utils.py:1227: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True - False - False - True - True -\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "\n",
    "# Prompt for extracting locations\n",
    "prompt = \"What are the locations mentioned in the following text: Chambéry, France and Lausanne, Switzerland - Python and Javascript devs - geospatial and business\\nAll open source.\\nGeospatial development is primarily Javascript (OpenLayers, Ext.js) and Python (Pylons, SQLAlchemy, etc.).\\nBusiness development is Python (OpenERP) ?\"\n",
    "\n",
    "# Tokenize the input\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate a response\n",
    "outputs = model.generate(input_ids, min_length=20)\n",
    "\n",
    "# Decode the output\n",
    "decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(decoded_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the locations mentioned in the text?\n",
      "Answer: \n",
      "Chambéry, France and Lausanne, Switzerland\n",
      "Question: What technologies are mentioned in the text?\n",
      "Answer: Pylons, SQLAlchemy, etc.).\n",
      "Question: What technical skills are mentioned in the text?\n",
      "Answer: Python and Javascript\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the question-answering pipeline\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "nlp = pipeline(\"question-answering\", model=model_name, tokenizer=model_name, max_length=512)\n",
    "\n",
    "# The context from which the model will extract information\n",
    "context = \"\"\"\n",
    "Chambéry, France and Lausanne, Switzerland - Python and Javascript devs - geospatial and business\n",
    "All open source.\n",
    "Geospatial development is primarily Javascript (OpenLayers, Ext.js) and Python (Pylons, SQLAlchemy, etc.).\n",
    "Business development is Python (OpenERP).\n",
    "\"\"\"\n",
    "\n",
    "# Questions you want the model to answer\n",
    "questions = [\n",
    "    \"What are the locations mentioned in the text?\",\n",
    "    \"What technologies are mentioned in the text?\",\n",
    "    \"What technical skills are mentioned in the text?\",\n",
    "]\n",
    "\n",
    "# Ask each question\n",
    "for question in questions:\n",
    "    result = nlp(question=question, context=context)\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {result['answer']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/busesibelkorkmaz/miniconda3/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:164: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the locations mentioned in the text?\n",
      "Answer: <pad> Chambéry, France and Lausanne, Switzerland</s>\n",
      "Question: What technologies and libraries are mentioned in the text?\n",
      "Answer: <pad> Javascript (OpenLayers, Ext.js) and Python (Pylons, SQLAlchemy, etc.)</s>\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "\n",
    "# The context from which the model will extract information\n",
    "context = \"\"\"\n",
    "Chambéry, France and Lausanne, Switzerland - Python and Javascript devs - geospatial and business\n",
    "All open source.\n",
    "Geospatial development is primarily Javascript (OpenLayers, Ext.js) and Python (Pylons, SQLAlchemy, etc.).\n",
    "Business development is Python (OpenERP).\n",
    "\"\"\"\n",
    "\n",
    "# Questions you want the model to answer\n",
    "questions = [\n",
    "    \"What are the locations mentioned in the text?\",\n",
    "    \"What technologies and libraries are mentioned in the text?\",\n",
    "    # \"What technical skills are mentioned in the text?\",\n",
    "]\n",
    "\n",
    "# Iterate over each question\n",
    "for question in questions:\n",
    "    # Concatenate the question and the context\n",
    "    input_text = \"question: \" + question + \" context: \" + context\n",
    "\n",
    "    # Encode the input text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    # Pass the input to the model and get the predicted answer\n",
    "    output = model.generate(input_ids, max_length=128)\n",
    "    answer = tokenizer.decode(output[0])\n",
    "\n",
    "    # Print the question and the predicted answer\n",
    "    print(\"Question:\", question)\n",
    "    print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiring_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73445"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hiring_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7163203b158b4fd7b52c4971a888b218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/75974 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def not_none(example):\n",
    "    return example['text'] is not None\n",
    "\n",
    "dataset[\"hiring\"] = dataset[\"hiring\"].filter(not_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3edc5dccf94e59b48daa74716e32ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/73445 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/datasets/utils/py_utils.py:1348\u001b[0m, in \u001b[0;36miflatmap_unordered\u001b[0;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     \u001b[39myield\u001b[39;00m queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39m0.05\u001b[39;49m)\n\u001b[1;32m   1349\u001b[0m \u001b[39mexcept\u001b[39;00m Empty:\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mget\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/multiprocess/managers.py:818\u001b[0m, in \u001b[0;36mBaseProxy._callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m conn\u001b[39m.\u001b[39msend((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id, methodname, args, kwds))\n\u001b[0;32m--> 818\u001b[0m kind, result \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mrecv()\n\u001b[1;32m    820\u001b[0m \u001b[39mif\u001b[39;00m kind \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m#RETURN\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/multiprocess/connection.py:258\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 258\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv_bytes()\n\u001b[1;32m    259\u001b[0m \u001b[39mreturn\u001b[39;00m _ForkingPickler\u001b[39m.\u001b[39mloads(buf\u001b[39m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/multiprocess/connection.py:422\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_recv_bytes\u001b[39m(\u001b[39mself\u001b[39m, maxsize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 422\u001b[0m     buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv(\u001b[39m4\u001b[39;49m)\n\u001b[1;32m    423\u001b[0m     size, \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m\"\u001b[39m\u001b[39m!i\u001b[39m\u001b[39m\"\u001b[39m, buf\u001b[39m.\u001b[39mgetvalue())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/multiprocess/connection.py:387\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39mwhile\u001b[39;00m remaining \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m     chunk \u001b[39m=\u001b[39m read(handle, remaining)\n\u001b[1;32m    388\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 73\u001b[0m\n\u001b[1;32m     70\u001b[0m counter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39m# dataset[\"hiring\"] = dataset[\"hiring\"].map(preprocess_text, num_proc=8)\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m dataset[\u001b[39m\"\u001b[39m\u001b[39mhiring\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataset[\u001b[39m\"\u001b[39;49m\u001b[39mhiring\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mmap(\u001b[39mlambda\u001b[39;49;00m x: parse_job_description(x, \u001b[39m\"\u001b[39;49m\u001b[39mloc\u001b[39;49m\u001b[39m\"\u001b[39;49m, counter), num_proc\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n\u001b[1;32m     74\u001b[0m counter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[39m# hiring_df[\"technologies\"] = hiring_df[\"clean_text\"].apply(lambda x: parse_job_description(x, \"tech\", counter))\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/datasets/arrow_dataset.py:580\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    579\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    581\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    582\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    583\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/datasets/arrow_dataset.py:545\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    539\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    540\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    541\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    542\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    543\u001b[0m }\n\u001b[1;32m    544\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 545\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    546\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    547\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/datasets/arrow_dataset.py:3180\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3172\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSpawning \u001b[39m\u001b[39m{\u001b[39;00mnum_proc\u001b[39m}\u001b[39;00m\u001b[39m processes\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   3173\u001b[0m \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[1;32m   3174\u001b[0m     disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   3175\u001b[0m     unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3178\u001b[0m     desc\u001b[39m=\u001b[39m(desc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m (num_proc=\u001b[39m\u001b[39m{\u001b[39;00mnum_proc\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3179\u001b[0m ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3180\u001b[0m     \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m iflatmap_unordered(\n\u001b[1;32m   3181\u001b[0m         pool, Dataset\u001b[39m.\u001b[39m_map_single, kwargs_iterable\u001b[39m=\u001b[39mkwargs_per_job\n\u001b[1;32m   3182\u001b[0m     ):\n\u001b[1;32m   3183\u001b[0m         \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m   3184\u001b[0m             shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/datasets/utils/py_utils.py:1354\u001b[0m, in \u001b[0;36miflatmap_unordered\u001b[0;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[1;32m   1351\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1352\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1353\u001b[0m     \u001b[39m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m-> 1354\u001b[0m     [async_result\u001b[39m.\u001b[39mget(timeout\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m) \u001b[39mfor\u001b[39;00m async_result \u001b[39min\u001b[39;00m async_results]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/datasets/utils/py_utils.py:1354\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1351\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1352\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1353\u001b[0m     \u001b[39m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m-> 1354\u001b[0m     [async_result\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39m0.05\u001b[39;49m) \u001b[39mfor\u001b[39;00m async_result \u001b[39min\u001b[39;00m async_results]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/multiprocess/pool.py:770\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    769\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[0;32m--> 770\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_success:\n\u001b[1;32m    772\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "\u001b[0;31mTimeoutError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import pipeline\n",
    "\n",
    "def parse_job_description(\n",
    "    row, \n",
    "    question:str,\n",
    "    counter: int,\n",
    "    ) -> str:\n",
    "    \n",
    "    counter +=1 \n",
    "    if counter % 100 == 0:\n",
    "        print(f\"{question} progress %{100*(counter/len(hiring_df))}\")\n",
    "\n",
    "    # # Initialize the tokenizer and model\n",
    "    # tokenizer = T5Tokenizer.from_pretrained(\"t5-base\", model_max_length=512)\n",
    "    # model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "\n",
    "    # # The context from which the model will extract information\n",
    "    # context = row[\"text\"]\n",
    "\n",
    "    # # Questions you want the model to answer\n",
    "    # questions = {\n",
    "    #     \"loc\": \"What are the locations mentioned in the text?\",\n",
    "    #     \"tech\": \"What technologies and libraries are mentioned in the text?\",\n",
    "    #     # \"What technical skills are mentioned in the text?\",\n",
    "    # }\n",
    "\n",
    "    # # Iterate over each question\n",
    "    # # Concatenate the question and the context\n",
    "    # input_text = \"question: \" + questions[question] + \" context: \" + context\n",
    "\n",
    "    # # Encode the input text\n",
    "    # input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    # # Pass the input to the model and get the predicted answer\n",
    "    # output = model.generate(input_ids, max_length=128)\n",
    "    # answer = tokenizer.decode(output[0])\n",
    "\n",
    "\n",
    "    # Initialize the question-answering pipeline\n",
    "    model_name = \"deepset/roberta-base-squad2\"\n",
    "    nlp = pipeline(\"question-answering\", model=model_name, tokenizer=model_name, max_length=512)\n",
    "\n",
    "    # The context from which the model will extract information\n",
    "    context = row[\"text\"]\n",
    "\n",
    "    # Questions you want the model to answer\n",
    "    questions = {\n",
    "        \"loc\": \"What are the locations mentioned in the text?\",\n",
    "        \"tech\": \"What technologies and libraries are mentioned in the text?\",\n",
    "        # \"What technical skills are mentioned in the text?\",\n",
    "    }\n",
    "\n",
    "    # Ask each question\n",
    "    result = nlp(question=questions[question], context=context)\n",
    "    print(result[\"answer\"])\n",
    "    # print(f\"Question: {question}\")\n",
    "    # print(f\"Answer: {result['answer']}\")\n",
    "\n",
    "    # Print the question and the predicted answer\n",
    "    # print(\"Question:\", question)\n",
    "    # print(\"Answer:\", answer)\n",
    "    if question ==  \"loc\":\n",
    "        key = \"location\"\n",
    "    else:\n",
    "        key = \"technologies\"\n",
    "\n",
    "    return {key: result[\"answer\"]}\n",
    "\n",
    "counter = 0\n",
    "# dataset[\"hiring\"] = dataset[\"hiring\"].map(preprocess_text, num_proc=8)\n",
    "\n",
    "dataset[\"hiring\"] = dataset[\"hiring\"].map(lambda x: parse_job_description(x, \"loc\", counter), num_proc=4)\n",
    "counter = 0\n",
    "# hiring_df[\"technologies\"] = hiring_df[\"clean_text\"].apply(lambda x: parse_job_description(x, \"tech\", counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa46df9eae114c2faf9749a5fd2eb4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/75974 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[\"hiring\"].save_to_disk(\"processed_hiring\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
